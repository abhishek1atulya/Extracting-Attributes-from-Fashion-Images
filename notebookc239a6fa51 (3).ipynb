{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ef2ab2f2",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2023-06-07T07:32:29.567521Z",
     "iopub.status.busy": "2023-06-07T07:32:29.567073Z",
     "iopub.status.idle": "2023-06-07T07:59:25.807939Z",
     "shell.execute_reply": "2023-06-07T07:59:25.806839Z"
    },
    "papermill": {
     "duration": 1616.247367,
     "end_time": "2023-06-07T07:59:25.810706",
     "exception": false,
     "start_time": "2023-06-07T07:32:29.563339",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:98: UserWarning: unable to load libtensorflow_io_plugins.so: unable to open file: libtensorflow_io_plugins.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so']\n",
      "caused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so: undefined symbol: _ZN3tsl6StatusC1EN10tensorflow5error4CodeESt17basic_string_viewIcSt11char_traitsIcEENS_14SourceLocationE']\n",
      "  warnings.warn(f\"unable to load libtensorflow_io_plugins.so: {e}\")\n",
      "/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:104: UserWarning: file system plugins are not loaded: unable to open file: libtensorflow_io.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so']\n",
      "caused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so: undefined symbol: _ZTVN10tensorflow13GcsFileSystemE']\n",
      "  warnings.warn(f\"file system plugins are not loaded: {e}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 14712 validated image filenames belonging to 7 classes.\n",
      "Found 3679 validated image filenames belonging to 7 classes.\n",
      "Epoch 1/20\n",
      "460/460 [==============================] - 121s 243ms/step - loss: 3.7002 - accuracy: 0.2984 - val_loss: 1.8180 - val_accuracy: 0.2955\n",
      "Epoch 2/20\n",
      "460/460 [==============================] - 71s 153ms/step - loss: 1.6205 - accuracy: 0.3580 - val_loss: 1.8159 - val_accuracy: 0.2955\n",
      "Epoch 3/20\n",
      "460/460 [==============================] - 69s 150ms/step - loss: 1.4733 - accuracy: 0.4190 - val_loss: 1.8169 - val_accuracy: 0.3264\n",
      "Epoch 4/20\n",
      "460/460 [==============================] - 61s 133ms/step - loss: 1.3319 - accuracy: 0.4784 - val_loss: 1.8275 - val_accuracy: 0.2191\n",
      "Epoch 5/20\n",
      "460/460 [==============================] - 63s 136ms/step - loss: 1.2003 - accuracy: 0.5349 - val_loss: 1.8382 - val_accuracy: 0.2191\n",
      "Epoch 6/20\n",
      "460/460 [==============================] - 62s 134ms/step - loss: 1.1062 - accuracy: 0.5695 - val_loss: 1.8438 - val_accuracy: 0.2191\n",
      "Epoch 7/20\n",
      "460/460 [==============================] - 63s 137ms/step - loss: 1.0151 - accuracy: 0.6093 - val_loss: 1.8435 - val_accuracy: 0.2191\n",
      "Epoch 8/20\n",
      "460/460 [==============================] - 61s 134ms/step - loss: 0.9211 - accuracy: 0.6460 - val_loss: 1.8533 - val_accuracy: 0.2191\n",
      "Epoch 9/20\n",
      "460/460 [==============================] - 62s 136ms/step - loss: 0.8549 - accuracy: 0.6773 - val_loss: 1.8543 - val_accuracy: 0.2191\n",
      "Epoch 10/20\n",
      "460/460 [==============================] - 63s 137ms/step - loss: 0.7772 - accuracy: 0.7026 - val_loss: 1.8579 - val_accuracy: 0.2191\n",
      "Epoch 11/20\n",
      "460/460 [==============================] - 62s 135ms/step - loss: 0.7148 - accuracy: 0.7291 - val_loss: 1.8743 - val_accuracy: 0.2191\n",
      "Epoch 12/20\n",
      "460/460 [==============================] - 64s 139ms/step - loss: 0.6711 - accuracy: 0.7463 - val_loss: 1.8675 - val_accuracy: 0.2191\n",
      "Epoch 13/20\n",
      "460/460 [==============================] - 63s 138ms/step - loss: 0.6209 - accuracy: 0.7745 - val_loss: 1.8764 - val_accuracy: 0.2191\n",
      "Epoch 14/20\n",
      "460/460 [==============================] - 63s 138ms/step - loss: 0.5940 - accuracy: 0.7840 - val_loss: 1.8802 - val_accuracy: 0.2191\n",
      "Epoch 15/20\n",
      "460/460 [==============================] - 64s 139ms/step - loss: 0.5451 - accuracy: 0.8027 - val_loss: 1.8832 - val_accuracy: 0.2191\n",
      "Epoch 16/20\n",
      "460/460 [==============================] - 71s 154ms/step - loss: 0.5203 - accuracy: 0.8123 - val_loss: 1.8911 - val_accuracy: 0.2191\n",
      "Epoch 17/20\n",
      "460/460 [==============================] - 62s 135ms/step - loss: 0.5043 - accuracy: 0.8222 - val_loss: 1.8970 - val_accuracy: 0.2191\n",
      "Epoch 18/20\n",
      "460/460 [==============================] - 62s 135ms/step - loss: 0.4958 - accuracy: 0.8246 - val_loss: 1.8891 - val_accuracy: 0.2191\n",
      "Epoch 19/20\n",
      "460/460 [==============================] - 61s 133ms/step - loss: 0.4386 - accuracy: 0.8412 - val_loss: 1.8941 - val_accuracy: 0.2191\n",
      "Epoch 20/20\n",
      "460/460 [==============================] - 63s 138ms/step - loss: 0.4261 - accuracy: 0.8527 - val_loss: 1.9060 - val_accuracy: 0.2191\n",
      "Found 5751 validated image filenames belonging to 1 classes.\n",
      "180/180 [==============================] - 34s 190ms/step\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import os\n",
    "import cv2\n",
    "# for dirname, _, filenames in os.walk('/kaggle/input/'):\n",
    "#     for filename in filenames:\n",
    "#         print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session\n",
    "# Load the data\n",
    "# Load the data\n",
    "train_data = pd.read_csv('/kaggle/input/extracting-attributes-from-fashion-images-2/train.csv')\n",
    "\n",
    "# Prepare the data\n",
    "X = train_data['file_name']  # Image file names\n",
    "y = train_data['label']  # Class labels\n",
    "# Split the data into training and validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2)\n",
    "# Define data augmentation and preprocessing\n",
    "train_datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "    preprocessing_function=tf.keras.applications.efficientnet.preprocess_input,\n",
    ")\n",
    "# Split the data into training and validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2)\n",
    "# Define data augmentation and preprocessing\n",
    "train_datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "    preprocessing_function=tf.keras.applications.efficientnet.preprocess_input,\n",
    ")\n",
    "val_datagen = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1./255)\n",
    "train = pd.DataFrame()\n",
    "train['file_name'] = X_train \n",
    "train['label'] = y_train\n",
    "# Convert numeric labels to strings\n",
    "train['label'] = train['label'].astype(str)\n",
    "\n",
    "# Create the train generator\n",
    "train_generator = train_datagen.flow_from_dataframe(\n",
    "    dataframe=train,\n",
    "    x_col='file_name',\n",
    "    y_col='label',\n",
    "    directory='/kaggle/input/extracting-attributes-from-fashion-images-2/train',\n",
    "    shuffle=True,\n",
    "    target_size=(100, 100),\n",
    "    batch_size=32,\n",
    "    class_mode='sparse'\n",
    ")\n",
    "valid = pd.DataFrame()\n",
    "valid['file_name'] = X_val \n",
    "valid['label'] = y_val\n",
    "# Convert numeric labels to strings\n",
    "valid['label'] = valid['label'].astype(str)\n",
    "val_generator = val_datagen.flow_from_dataframe(\n",
    "    dataframe=valid,\n",
    "    x_col=\"file_name\",\n",
    "    y_col=\"label\",\n",
    "    directory='/kaggle/input/extracting-attributes-from-fashion-images-2/train',\n",
    "    #subset=\"validation\",  # Use the validation subset of the data\n",
    "    shuffle=True,\n",
    "    target_size=(100, 100),  # Update the target size if needed\n",
    "    batch_size=32,\n",
    "    class_mode='sparse'\n",
    ")\n",
    "# Define the CNN model architecture\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Conv2D(32, 3, activation='relu', input_shape=(100, 100, 3)),\n",
    "    tf.keras.layers.MaxPooling2D(),\n",
    "    tf.keras.layers.Conv2D(64, 3, activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(),\n",
    "    tf.keras.layers.Conv2D(64, 3, activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    tf.keras.layers.Dense(7, activation='softmax')\n",
    "])\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "# Train the model\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    validation_data=val_generator,\n",
    "    epochs=20\n",
    ")\n",
    "test = pd.read_csv('/kaggle/input/extracting-attributes-from-fashion-images-2/sample_submission.csv')\n",
    "test_generator = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "    preprocessing_function=tf.keras.applications.efficientnet.preprocess_input,\n",
    ")\n",
    "test['label'] = test['label'].astype(str)\n",
    "test_images = test_generator.flow_from_dataframe(\n",
    "    dataframe=test,\n",
    "    x_col='file_name',\n",
    "    y_col='label',\n",
    "    directory='/kaggle/input/extracting-attributes-from-fashion-images-2/test',\n",
    "    target_size=(100,100),\n",
    "    batch_size=32,\n",
    "    shuffle=False\n",
    ")\n",
    "pred = model.predict(test_images)\n",
    "pred = np.argmax(pred,axis=1)\n",
    "sub = pd.read_csv('/kaggle/input/extracting-attributes-from-fashion-images-2/sample_submission.csv')\n",
    "sub['label'] = pred\n",
    "sub.to_csv('/kaggle/working/file1.csv')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 1630.524515,
   "end_time": "2023-06-07T07:59:29.572835",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-06-07T07:32:19.048320",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
